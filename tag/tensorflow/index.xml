<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Tensorflow | V S Abhinav Rahul Gandrakota</title>
    <link>https://example.com/tag/tensorflow/</link>
      <atom:link href="https://example.com/tag/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    <description>Tensorflow</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 12 Dec 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hu48098076ec83a1da7a68860ddba0d02f_33231_512x512_fill_lanczos_center_3.png</url>
      <title>Tensorflow</title>
      <link>https://example.com/tag/tensorflow/</link>
    </image>
    
    <item>
      <title>VRFB Stack Temperature Prediction</title>
      <link>https://example.com/project/vrfb-temp-prediction/</link>
      <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/vrfb-temp-prediction/</guid>
      <description>&lt;p&gt;Redox Flow Batteries have risen in popularity in recent years as a large-scale energy storage solution. Efficiency of the battery storage system relies on minimizing power loss, which in turn is dependent on predicting VRFB stack temperature and keeping it within a safe limit so as to prevent thermal precipitation. We have predicted variation of stack temperature with time duration of a practical 1kW 6kWh VRFB system dataset under four different operating current levels (40, 45, 50, and 60A) keeping a constant electrolyte flow rate of 180 ml/sec for both charging and discharging conditions. &lt;br&gt;
&lt;br&gt;
Here, we have used both Polynomial Regression and LSTM methods to accurately predict the stack temperature of the battery during charging and discharging profiles. The prediction accuracy of the algorithm was tested using regression metrics such as Root Mean Square Error (RMSE), Mean Absolute Error (MAE) and Correlation Coefficient (R2). &lt;br&gt;
&lt;br&gt;
In the case of Polynomial Regression, we created models for degrees 0-9 and implemented it on the dataset. We used gradient descent to update the weights at each iteration. The MSE error was calculated every 5000 iterations and the model was run for a total of 50000 iterations.&lt;br&gt;
&lt;br&gt;
For LSTM, We used the ‘train_test_split’ function within Scikit-learn to split the dataset 70:30 for training and testing respectively. We did not shuffle the data in this case as LSTM’s need sequential data for performing time series prediction. We reshaped the training and testing temperature data and performed Min-Max scaling using the ‘MinMaxScaler’ function within Scikit-learn so as to bring all temperature values within the range [0,1]. Min-Max scaling is performed when it is required to capture small variance in features and also for sparse data where the zero value needs to be preserved. &lt;br&gt;
&lt;br&gt;
We then used the ‘TimeseriesGenerator’ module within Tensorflow to generate a time series with number of features as 1 and number of inputs as 5. Essentially this means that the model will use 5 values from the data to predict the 6th value in the data. We then created an LSTM model having 100 hidden layers which takes an input of shape (5,1) and uses a ReLU activation function at the output layer finally giving an output of size 1. The Adam optimizer with a learning rate of 0.001, β1 = 0.9, β2 = 0.999, ϵ = 10-8 was used with no weight decay. MSE error was used as the loss function. &lt;br&gt;
&lt;br&gt;
The model was then trained on the training dataset for 50 epochs and the loss per epoch was plotted. We then used the model for prediction over the length of the entire dataset and the predicted values were stored in an array before being rescaled to the original size. The array was added later as an extra column within the dataset. The final MSE, RMSE and R2 errors were calculated and tabulated. We then plotted the algorithm performance and the parameter performance graphs. &lt;br&gt;
&lt;br&gt;
For the obtained results and graphs, check out the paper!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Audio Based Language Identification</title>
      <link>https://example.com/project/language-identification/</link>
      <pubDate>Fri, 09 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/language-identification/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Language Identification (LI) is an important first step in several speech processing systems and the recommended initial step for Automatic Speech Recognition (ASR). LI is needed for ASR as ASR based systems cannot parse the uttered language in multilingual contexts causing failure in speech recognition. LI allows these systems to automatically recognize the speaker&amp;rsquo;s language and change its language settings accordingly. We propose an attention based convolutional recurrent neural network (CRNN with Attention) that works on Mel-frequency Cepstral Coefficient (MFCC) features of audio specimens. Additionally, we reproduce some state-of-the-art approaches, namely Convolutional Neural Network (CNN) and Convolutional Recurrent Neural Network (CRNN), and compare them to our proposed method. &lt;br&gt;
\&lt;/p&gt;
&lt;h1 id=&#34;why-deep-learning-approach&#34;&gt;Why Deep Learning Approach?&lt;/h1&gt;
&lt;p&gt;Over the years, studies have utilized many prosodic and acoustic features to construct machine learning models for LI systems. Every language is composed of phonemes, which are distinct unit of sounds in that language, such as &amp;lsquo;b&amp;rsquo; of black and &amp;lsquo;g&amp;rsquo; of green. Several prosodic and acoustic features are based on phonemes, which become the underlying features on whom the performance of the statistical model depends. If two languages have many overlapping phonemes, then identifying them becomes a challenging task for a classifier. Due to such drawbacks several studies have switched over to using Deep Neural Networks (DNNs) to harness their novel auto-extraction techniques. &lt;br&gt;
\&lt;/p&gt;
&lt;h1 id=&#34;dataset&#34;&gt;Dataset&lt;/h1&gt;
&lt;p&gt;In the past two decades, development of LID methods has been largely fostered through NIST Language Evaluations (LREs). As a result, the most popular benchmarks for evaluating new LID models and methods are NIST LRE evaluation dataset. The NIST LREs dataset mostly contains narrow-band telephone speech. As the NIST LRE dataset is not freely available and we wanted more modern audio sources, we decided to proceed with IndicTTS dataset, which is open sourced. &lt;br&gt;
&lt;br&gt;
IndicTTS is a special corpus of Indian languages covering 13 major languages of India. These include Bengali, Hindi, Marathi, Tamil, Telugu, Assamese, Bodo(India), Gujarati, Kannada, Malayalam, Manipuri, Odia and Rajasthani. It comprises of 10000+ spoken sentences/utterances each of mono and English recorded by both Male and Female native speakers. Speech waveform files are available in .wav format along with the corresponding text. &lt;br&gt;
\&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
